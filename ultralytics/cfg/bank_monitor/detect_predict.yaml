# 需要修改的参数
task: "detect"
mode: "predict"
model:
source: # (str, optional) source directory for images or videos


batch: 16           # (int) number of images per batch (-1 for AutoBatch)
conf: 0.25          # (float, optional) object confidence threshold for detection (default 0.25 predict, 0.001 val)
iou: 0.7            # (float) intersection over union (IoU) threshold for NMS
data:               # (str, optional) path to data file, i.e. coco8.yaml
vid_stride: 1       # (int) video frame-rate stride
verbose: True       # (bool) whether to print verbose output，控制台是否打印信息

# Result save settings -------------------------------------------------------------------------------------------------
save: False         # (bool) save predict results
project:            # (str, optional) project name. 为空保存到 test/tmp/runs/task 文件夹下
name:               # (str, optional) experiment name, results saved to 'project/name' directory
exist_ok: False     # (bool) whether to overwrite existing experiment
save_dir:           # 保存的路径，为空就按默认设置，保存在 run/project/name/task/mode_num 文件夹下
save_frames: False  # (bool) save predicted individual video frames
save_txt: False     # (bool) save results as .txt file
save_conf: False    # (bool) save results with confidence scores
save_crop: False    # (bool) save cropped images with results

# Visualize settings ---------------------------------------------------------------------------------------------------
show: False           # (bool) show predicted images and videos if environment allows
show_labels: True     # (bool) show prediction labels, i.e. 'person'
show_conf: True       # (bool) show prediction confidence, i.e. '0.99'
show_boxes: True      # (bool) show prediction boxes
line_width:           # (int, optional) line width of the bounding boxes. Scaled to image size if None.

# 可能修改的参数
classes:                # (int | list[int], optional) filter results by class, i.e. classes=0, or classes=[0,2,3]
imgsz: 640              # (int | list) input images size as int for train and val modes, or list[w,h] for predict and export modes
device: 0               # (int | str | list, optional) device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu
stream_buffer: False    # (bool) buffer all streaming frames (True) or return the most recent frame (False)
dnn: False              # (bool) use OpenCV DNN for ONNX inference
half: False             # (bool) use half precision (FP16)

# 基本不用修改的参数
visualize: False        # (bool) visualize model features，用于可视化模型推理中每一层的特征
augment: False          # (bool) apply image augmentation to prediction sources
embed:                  # (list[int], optional) return feature vectors/embeddings from given layers
agnostic_nms: False     # (bool) class-agnostic NMS，False考虑检测框的类别进行极大值抑制（True会导致几类同框只选最大那个框）
max_det: 300            # (int) maximum number of detections per image
crop_fraction: 1.0      # (float) image crop fraction for classification (0.1-1), 1.0 means no crop, must be greater than 0.
retina_masks: False     # (bool) use high-resolution segmentation masks
